{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](../graphics/solutions-microsoft-logo-small.png)\n",
    "\n",
    "# Data Science Projects with SQL Server Machine Learning Services\n",
    "\n",
    "## 03 Data Acquisition and Understanding\n",
    "\n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> \n",
    "<dl>\n",
    "  <dt>Course Outline</dt>\n",
    "  <dt>1 Overview and Course Setup</dt>\n",
    "  <dt>2 Business Understanding</dt>\n",
    "  <dt>3 Data Acquisition and Understanding <i>(This section)</i></dt>\n",
    "        <dd>3.1 Loading Data into the Solution</dd>\n",
    "        <dd>3.2 Data Exploration and Profiling</dd>\n",
    "  <dt>4 Modeling</dt>\n",
    "  <dt>5 Deployment</dt>\n",
    "  <dt>6 Customer Acceptance and Model Retraining</dt>\n",
    "<dl>\n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Business Intelligence you're familiar with Extract, Transform and Load(ETL) to prepare data for historical, pre-aggregated storage for ad-hoc queries. For Machine Learning, it's more common to extract the data, load it ito a source, and then transform the data as late as possible in the process (ELT). This allows the most fidelity within the process. \n",
    "\n",
    "There are multiple ways to ingest data, depending on the intended location. For SQL Server, data is often generated within base tables by applications, and other data can be loaded via the bcp program or SQL Server Integration Services. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"../graphics/cortanalogo.png\"><b>3.1 Loading Data into the Solution</b></p>\n",
    "\n",
    "In the Data Acquisition and Understanding phase of your process you ingest or access data from various locations to answer the questions the organization has asked. In most cases, this data will be in multiple locations. Once the data is ingested into the system, you’ll need to examine it to see what it holds. All data needs cleaning, so after the inspection phase, you’ll replace missing values, add and change columns. You’ll cover more extensive Data Wrangling tasks in other courses. In this section, you’ll use a single Database dataset to train your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals for Data Acquisition and Understanding\n",
    "\n",
    "- Produce a clean, high-quality data set whose relationship to the target variables is understood. Locate the data set in the appropriate analytics environment so you are ready to model.\n",
    "- Develop a solution architecture of the data pipeline that refreshes and scores the data regularly.\n",
    "\n",
    "### How to do it\n",
    "\n",
    "- Ingest the data into the target analytic environment.\n",
    "- Explore the data to determine if the data quality is adequate to answer the question.\n",
    "- Set up a data pipeline to score new or regularly refreshed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"../graphics/aml-logo.png\"><b>Activity: Restore the Database</b></p>\n",
    "\n",
    "- Run SSMS or Visual Studio, connect to your SQL Server Instance, and open a new query window. The dataset used in this course is hosted in a SQL Server table.The table contains rental data from previous years. The backup (.bak) file is in the `./data` directory called **TutorialDB.bak**, and save it on a location that SQL Server can access, for example in the folder where SQL Server is installed. \n",
    "\n",
    "Example path: *C:\\Program Files\\Microsoft SQL Server\\MSSQL13.MSSQLSERVER\\MSSQL\\Backup*\n",
    "\n",
    "- Once you have the file saved, open SSMS and a new query window to run the following commands to restore the DB. Make sure to modify the file paths and server name in the script:\n",
    "\n",
    "<pre>\n",
    "USE master;\n",
    "GO\n",
    "RESTORE DATABASE TutorialDB\n",
    " FROM DISK = 'C:\\Program Files\\Microsoft SQL Server\\MSSQL14.MSSQLSERVER\\MSSQL\\Backup\\TutorialDB.bak'\n",
    " WITH\n",
    " MOVE 'TutorialDB' TO 'C:\\Program Files\\Microsoft SQL Server\\MSSQL14.MSSQLSERVER\\MSSQL\\DATA\\TutorialDB.mdf'\n",
    ",MOVE 'TutorialDB_log' TO 'C:\\Program Files\\Microsoft SQL Server\\MSSQL14.MSSQLSERVER\\MSSQL\\DATA\\TutorialDB.ldf';\n",
    "GO\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A table named rental_data containing the dataset should exist in the restored SQL Server database. You can verify this by querying the table in SSMS:\n",
    "\n",
    "<pre>\n",
    "USE tutorialdb;\n",
    "SELECT * FROM [dbo].[rental_data];\n",
    "</pre>\n",
    "\n",
    "You should see a row of data returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"../graphics/cortanalogo.png\"><b>3.2 Data Exploration and Profiling</b></p>\n",
    "\n",
    "With the data located and loaded, you can now begin the exploration. You need to know the \"shape\" of the data, some basic statistics, and very importantly, any missing values.\n",
    "\n",
    "You can use standard Transact-SQL statements for a majority of the exploration. The SQL language has a rich, declarative structure that will provide most of the information you need.\n",
    "\n",
    "There are other options for for exploring your data, such as R or Python. R is a data-first language, and most Data Scientists are familiar with using it to explore data.\n",
    "\n",
    "You can use SQL Server Stored Procedures to hold the R code and run it within SQL Server ML Services as you saw in the previous module. You can also use a series of R Library calls to query the data held in SQL Server and work with it locally to the Data Scientist's workstation in a traditional fashion.\n",
    "\n",
    "In the graphic below, the Data Scientist works with R locally, and once they determine a good model, deploy that to SQL Server. Clients use the Model by calling a standard SQL Server Stored Procedure, no R client is needed on their machine or device:\n",
    "\n",
    "<p>\n",
    "<img src=\"../graphics/MLServerArchitecture.png\" width=\"500\">\n",
    "<p>\n",
    "\n",
    "You'll explore the data with this process next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"../graphics/aml-logo.png\"><b>Activity: Explore SQL Server Data using R</b></p>\n",
    "\n",
    "Step 2.2 Access the data from SQL Server using R\n",
    "\n",
    "- Open a new R Interactive Window in Visual Studio and run the following R Code. Replace \"MYSQLSERVER\" with the name of your database instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection string to connect to SQL Server instance. \n",
    "# Unless you have a SQL Server that you can access using\n",
    "# Jupyter Notebooks, then you should run this code on your \n",
    "# local system. You can see the Notebooks-Only version, check \n",
    "# the last cell.\n",
    "\n",
    "connStr <- paste(\"Driver=SQL Server; Server=\", \"MYSQLSERVER\", \n",
    "                \";Database=\", \"Tutorialdb\", \";Trusted_Connection=true;\", sep = \"\");\n",
    "\n",
    "# Get the data from a SQL Server Table\n",
    "SQL_rentaldata <- RxSqlServerData(table = \"dbo.rental_data\",\n",
    "                              connectionString = connStr, returnDataFrame = TRUE);\n",
    "\n",
    "# Import the data into a data frame\n",
    "rentaldata <- rxImport(SQL_rentaldata);\n",
    "\n",
    "# Let's see the structure of the data and the top rows\n",
    "# Ski rental data, giving the number of ski rentals on a given date\n",
    "head(rentaldata);\n",
    "str(rentaldata);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What other explorations can you do? How can you leverage graphical outputs to further show the layout of the data? \n",
    "\n",
    "- Can you show the missing data?\n",
    "\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"../graphics/thinking.jpg\"><b>For Further Study</b></p>\n",
    "\n",
    "- Data Acquisition and Understand Reference: https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/lifecycle-data \n",
    "\n",
    "Next, Continue to *04 - Environments and Deployment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>ï..Year</th><th scope=col>Month</th><th scope=col>Day</th><th scope=col>RentalCount</th><th scope=col>WeekDay</th><th scope=col>Holiday</th><th scope=col>Snow</th><th scope=col>FHoliday</th><th scope=col>FSnow</th><th scope=col>FWeekDay</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2014</td><td>1   </td><td>20  </td><td>445 </td><td>2   </td><td>1   </td><td>0   </td><td>1   </td><td>0   </td><td>2   </td></tr>\n",
       "\t<tr><td>2014</td><td>2   </td><td>13  </td><td> 40 </td><td>5   </td><td>0   </td><td>0   </td><td>0   </td><td>0   </td><td>5   </td></tr>\n",
       "\t<tr><td>2013</td><td>3   </td><td>10  </td><td>456 </td><td>1   </td><td>0   </td><td>0   </td><td>0   </td><td>0   </td><td>1   </td></tr>\n",
       "\t<tr><td>2014</td><td>3   </td><td>31  </td><td> 38 </td><td>2   </td><td>0   </td><td>0   </td><td>0   </td><td>0   </td><td>2   </td></tr>\n",
       "\t<tr><td>2014</td><td>4   </td><td>24  </td><td> 23 </td><td>5   </td><td>0   </td><td>0   </td><td>0   </td><td>0   </td><td>5   </td></tr>\n",
       "\t<tr><td>2015</td><td>2   </td><td>11  </td><td> 42 </td><td>4   </td><td>0   </td><td>0   </td><td>0   </td><td>0   </td><td>4   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " ï..Year & Month & Day & RentalCount & WeekDay & Holiday & Snow & FHoliday & FSnow & FWeekDay\\\\\n",
       "\\hline\n",
       "\t 2014 & 1    & 20   & 445  & 2    & 1    & 0    & 1    & 0    & 2   \\\\\n",
       "\t 2014 & 2    & 13   &  40  & 5    & 0    & 0    & 0    & 0    & 5   \\\\\n",
       "\t 2013 & 3    & 10   & 456  & 1    & 0    & 0    & 0    & 0    & 1   \\\\\n",
       "\t 2014 & 3    & 31   &  38  & 2    & 0    & 0    & 0    & 0    & 2   \\\\\n",
       "\t 2014 & 4    & 24   &  23  & 5    & 0    & 0    & 0    & 0    & 5   \\\\\n",
       "\t 2015 & 2    & 11   &  42  & 4    & 0    & 0    & 0    & 0    & 4   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "ï..Year | Month | Day | RentalCount | WeekDay | Holiday | Snow | FHoliday | FSnow | FWeekDay | \n",
       "|---|---|---|---|---|---|\n",
       "| 2014 | 1    | 20   | 445  | 2    | 1    | 0    | 1    | 0    | 2    | \n",
       "| 2014 | 2    | 13   |  40  | 5    | 0    | 0    | 0    | 0    | 5    | \n",
       "| 2013 | 3    | 10   | 456  | 1    | 0    | 0    | 0    | 0    | 1    | \n",
       "| 2014 | 3    | 31   |  38  | 2    | 0    | 0    | 0    | 0    | 2    | \n",
       "| 2014 | 4    | 24   |  23  | 5    | 0    | 0    | 0    | 0    | 5    | \n",
       "| 2015 | 2    | 11   |  42  | 4    | 0    | 0    | 0    | 0    | 4    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  ï..Year Month Day RentalCount WeekDay Holiday Snow FHoliday FSnow FWeekDay\n",
       "1 2014    1     20  445         2       1       0    1        0     2       \n",
       "2 2014    2     13   40         5       0       0    0        0     5       \n",
       "3 2013    3     10  456         1       0       0    0        0     1       \n",
       "4 2014    3     31   38         2       0       0    0        0     2       \n",
       "5 2014    4     24   23         5       0       0    0        0     5       \n",
       "6 2015    2     11   42         4       0       0    0        0     4       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in rxImport(SQL_rentaldata): could not find function \"rxImport\"\n",
     "output_type": "error",
     "traceback": [
      "Error in rxImport(SQL_rentaldata): could not find function \"rxImport\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "## Activity: Explore SQL Server Data using R\n",
    "\n",
    "# Connection string to connect to SQL Server instance - Replace WIN2K16DEV with your \n",
    "# SQL Server Instance Name\n",
    "#connStr <- paste(\"Driver=SQL Server; Server=\", \"WIN2K16DEV\",\n",
    "                #\";Database=\", \"Tutorialdb\", \";Trusted_Connection=true;\", sep = \"\");\n",
    "# Get the data from a SQL Server Table\n",
    "#SQL_rentaldata <- RxSqlServerData(table = \"dbo.rental_data\",\n",
    "                              #connectionString = connStr, returnDataFrame = TRUE);\n",
    "\n",
    "# For Jupyter Notebooks, you can just use a file source \n",
    "SQL_rentaldata <- read.csv(\"../data/TutorialDB.csv\", header = TRUE)\n",
    "head(SQL_rentaldata)\n",
    "\n",
    "# Import the data into a data frame\n",
    "rentaldata <- rxImport(SQL_rentaldata);\n",
    "\n",
    "# Let's see the structure of the data and the top rows\n",
    "# Ski rental data, giving the number of ski rentals on a given date\n",
    "head(rentaldata);\n",
    "str(rentaldata);\n",
    "\n",
    "## Activity:Set three Features to Categorical Data using R\n",
    "# Changing the three factor columns to factor types\n",
    "# This helps when building the model because we are explicitly saying that these values are categorical\n",
    "rentaldata$Holiday <- factor(rentaldata$Holiday);\n",
    "rentaldata$Snow <- factor(rentaldata$Snow);\n",
    "rentaldata$WeekDay <- factor(rentaldata$WeekDay);\n",
    "\n",
    "#Visualize the dataset after the change\n",
    "str(rentaldata);\n",
    "\n",
    "## Activity: Create an Experiment with two Algorithms\n",
    "# Split the dataset into 2 different sets:\n",
    "# One set for training the model and the other for validating it\n",
    "train_data = rentaldata[rentaldata$Year < 2015,];\n",
    "test_data = rentaldata[rentaldata$Year == 2015,];\n",
    "head(train_data)\n",
    "head(test_data)\n",
    "\n",
    "# Use this column to check the quality of the prediction against actual values\n",
    "actual_counts <- test_data$RentalCount;\n",
    "\n",
    "# Model 1: Use rxLinMod to create a linear regression model. We are training the data using the training data set\n",
    "model_linmod <- rxLinMod(RentalCount ~ Month + Day + WeekDay + Snow + Holiday, data = train_data);\n",
    "\n",
    "# Model 2: Use rxDTree to create a decision tree model. We are training the data using the training data set\n",
    "model_dtree <- rxDTree(RentalCount ~ Month + Day + WeekDay + Snow + Holiday, data = train_data);\n",
    "\n",
    "# Use the models you just created to predict using the test data set \n",
    "# that enables you to compare actual values of RentalCount from the two models and compare to the actual values in the test data set:\n",
    "predict_linmod <- rxPredict(model_linmod, test_data, writeModelVars = TRUE, extraVarsToWrite = c(\"Year\"));\n",
    "\n",
    "predict_dtree <- rxPredict(model_dtree, test_data, writeModelVars = TRUE, extraVarsToWrite = c(\"Year\"));\n",
    "\n",
    "# Look at the top rows of the two prediction data sets:\n",
    "head(predict_linmod);\n",
    "head(predict_dtree);\n",
    "\n",
    "# Plot the difference between actual and predicted values for both models to compare accuracy:\n",
    "par(mfrow = c(2, 1));\n",
    "plot(predict_linmod$RentalCount_Pred - predict_linmod$RentalCount, main = \"Difference between actual and predicted. rxLinmod\");\n",
    "plot(predict_dtree$RentalCount_Pred - predict_dtree$RentalCount, main = \"Difference between actual and predicted. rxDTree\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
